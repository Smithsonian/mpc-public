{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ef42b60",
   "metadata": {},
   "source": [
    "# Initial Orbit Determination with `digest2`\n",
    "\n",
    "#### This tutorial demonstrates how to use the `digest2` Python package for NEO orbit classification from short-arc astrometric tracklets.\n",
    "\n",
    "`digest2` is a fast orbit classifier that assigns pseudo-probability scores (0–100) to astrometric tracklets for each of 14 orbit classes (NEO, Main Belt, Mars Crosser, etc.). It is the primary tool used by the Minor Planet Center to decide which tracklets are posted to the [NEO Confirmation Page (NEOCP)](https://minorplanetcenter.net/iau/NEO/toconfirm_tabular.html) for follow-up.\n",
    "\n",
    "This can be useful if you want to:\n",
    "- Quickly classify newly observed tracklets before submitting to the MPC\n",
    "- Prioritize follow-up observations of potential NEO discoveries\n",
    "- Understand how the MPC evaluates NEOCP candidates\n",
    "- Incorporate orbit classification into automated survey pipelines\n",
    "\n",
    "**References:**\n",
    "- Keys et al. 2019,  ([\"The digest2 NEO Classification Code\"](https://ui.adsabs.harvard.edu/abs/2019PASP..131f4501K/abstract))\n",
    "- Veres et al. 2023, ([\"Improvement of Digest2 NEO Classification Code-utilizing the Astrometry Data Exchange Standard\"](https://ui.adsabs.harvard.edu/abs/2023PASP..135j4505V/abstract))\n",
    "- Veres et al. 2025, ([\"Improving the discovery of near-Earth objects with machine-learning methods\"](https://ui.adsabs.harvard.edu/abs/2025A%26A...698A.242V/abstract))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "env-setup",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "To run this notebook, you need a Python environment (>= 3.9) with `digest2` and its dependencies installed. We recommend creating a dedicated conda environment and registering it as a Jupyter kernel:\n",
    "\n",
    "```bash\n",
    "# Create and activate environment\n",
    "conda create -n digest2-dev python=3.11 -y\n",
    "conda activate digest2-dev\n",
    "\n",
    "# Install digest2 and notebook dependencies\n",
    "pip install digest2 requests ipykernel\n",
    "\n",
    "# Register as a Jupyter kernel\n",
    "python -m ipykernel install --user --name digest2-dev --display-name \"Python (digest2-dev)\"\n",
    "```\n",
    "\n",
    "Then open this notebook in Jupyter and select **Kernel > Change Kernel > Python (digest2-dev)**.\n",
    "\n",
    "If you are working from a local clone of the repository and want to install that, replace `pip install digest2` with:\n",
    "\n",
    "```bash\n",
    "cd mpc-public/digest2\n",
    "pip install '.[test]' requests ipykernel\n",
    "```\n",
    "\n",
    "The `digest2` Python package wraps a C scoring engine. Pre-built wheels are available on PyPI for common platforms (Linux, macOS, Windows), so most users get a ready-to-use binary with `pip install digest2`. If no wheel matches your platform or Python version, pip will automatically compile the C code from the source distribution - this requires a local C compiler (e.g., gcc or clang) but no external C libraries such as libxml2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ddf227",
   "metadata": {},
   "source": [
    "# Import\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd6fc6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from digest2 import Digest2, Observation, classify, ClassificationResult\n",
    "from digest2.observation import parse_mpc80_file, parse_ades_xml\n",
    "from dataclasses import fields\n",
    "import requests\n",
    "import tempfile\n",
    "import os\n",
    "import atexit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740bc49f",
   "metadata": {},
   "source": [
    "# Setup: Download Sample Data\n",
    "\n",
    "`digest2` requires an observatory codes file (`digest2.obscodes`) to look up parallax constants for each observatory. \n",
    " - We download this from the MPC's [Observatory Codes API](https://docs.minorplanetcenter.net/mpc-ops-docs/apis/obscodes/) in the flat-file format.\n",
    " - Because the code needs to know where this is, we can either save that information into an environmental variable, `DIGEST2_OBSCODES`, or pass in the path at the time of execution. In this notebook we'll typically pass in `obscodes_path`.\n",
    "\n",
    "We also create sample observation files in both MPC 80-column format and ADES XML format, and store them in the same temp-directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002f2f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observatory codes downloaded to: /var/folders/67/j23cbc8x5r3b_1cy48v0rf4m0000gq/T/digest2_tutorial_vcmsech_/digest2.obscodes\n",
      "  (2679 lines)\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary directory for our working files\n",
    "tmpdir = tempfile.mkdtemp(prefix=\"digest2_tutorial_\")\n",
    "atexit.register(lambda: __import__('shutil').rmtree(tmpdir, ignore_errors=True))\n",
    "\n",
    "# Download observatory codes from the MPC obscodes API (required by digest2)\n",
    "# We request the flat-file format (\"ObsCodes.html\") which digest2 can parse directly.\n",
    "# See: https://docs.minorplanetcenter.net/mpc-ops-docs/apis/obscodes/\n",
    "response = requests.get(\n",
    "    \"https://data.minorplanetcenter.net/api/obscodes\",\n",
    "    json={\"format\": \"ObsCodes.html\"}\n",
    ")\n",
    "response.raise_for_status()\n",
    "\n",
    "obscodes_path = os.path.join(tmpdir, \"digest2.obscodes\")\n",
    "with open(obscodes_path, \"w\") as f:\n",
    "    f.write(response.text)\n",
    "print(f\"Observatory codes downloaded to: {obscodes_path}\")\n",
    "print(f\"  ({len(response.text.splitlines())} lines)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a66006b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample .obs file: /var/folders/67/j23cbc8x5r3b_1cy48v0rf4m0000gq/T/digest2_tutorial_vcmsech_/sample.obs\n",
      "Multiple .obs file: /var/folders/67/j23cbc8x5r3b_1cy48v0rf4m0000gq/T/digest2_tutorial_vcmsech_/multiple.obs\n",
      "Sample .xml file: /var/folders/67/j23cbc8x5r3b_1cy48v0rf4m0000gq/T/digest2_tutorial_vcmsech_/sample.xml\n"
     ]
    }
   ],
   "source": [
    "# Sample MPC 80-column observation file: 3 observations of 2016 SK99 from G96 (Mt. Lemmon)\n",
    "sample_obs_content = \"\"\"     K16S99K 1C2022 12 25.38496508 32 36.283+17 10 35.94         21.98GV     G96\n",
    "     K16S99K 1C2022 12 25.39527308 32 35.635+17 10 37.27         21.72GV     G96\n",
    "     K16S99K 1C2022 12 25.40040208 32 35.473+17 10 37.38         21.31GV     G96\n",
    "\"\"\"\n",
    "\n",
    "sample_obs_path = os.path.join(tmpdir, \"sample.obs\")\n",
    "with open(sample_obs_path, \"w\") as f:\n",
    "    f.write(sample_obs_content)\n",
    "\n",
    "# Sample MPC 80-column observation file containing multiple tracklets\n",
    "multiple_obs_content = \\\n",
    "\"\"\"     K16S99K 1C2022 12 25.38496508 32 36.283+17 10 35.94         21.98GV     G96\n",
    "     K16S99K 1C2022 12 25.39527308 32 35.635+17 10 37.27         21.72GV     G96\n",
    "     K16S99K 1C2022 12 25.40040208 32 35.473+17 10 37.38         21.31GV     G96\n",
    "     K17R88L 1C2023 11 24.28496518 31 46.283+26 20 35.94         20.38GV     G96\n",
    "     K17R88L 1C2023 11 24.29527318 31 45.635+26 20 37.27         20.52GV     G96\n",
    "     K17R88L 1C2023 11 24.30040218 31 45.473+26 20 37.38         20.71GV     G96\n",
    "\"\"\"\n",
    "\n",
    "multiple_obs_path = os.path.join(tmpdir, \"multiple.obs\")\n",
    "with open(multiple_obs_path, \"w\") as f:\n",
    "    f.write(multiple_obs_content)\n",
    "\n",
    "# Sample ADES XML observation file (same object, richer metadata)\n",
    "sample_xml_content = \"\"\"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<ades version=\"2017\">\n",
    "      <optical>\n",
    "        <provID>2016 SK99</provID>\n",
    "        <trkSub>C8QY322</trkSub>\n",
    "        <mode>CCD</mode>\n",
    "        <stn>G96</stn>\n",
    "        <obsTime>2022-12-25T09:14:20.991Z</obsTime>\n",
    "        <ra>128.151180</ra>\n",
    "        <dec>17.176650</dec>\n",
    "        <rmsRA>0.247</rmsRA>\n",
    "        <rmsDec>0.301</rmsDec>\n",
    "        <astCat>Gaia2</astCat>\n",
    "        <mag>21.98</mag>\n",
    "        <band>G</band>\n",
    "      </optical>\n",
    "      <optical>\n",
    "        <provID>2016 SK99</provID>\n",
    "        <trkSub>C8QY322</trkSub>\n",
    "        <mode>CCD</mode>\n",
    "        <stn>G96</stn>\n",
    "        <obsTime>2022-12-25T09:29:11.606Z</obsTime>\n",
    "        <ra>128.148480</ra>\n",
    "        <dec>17.177020</dec>\n",
    "        <rmsRA>0.431</rmsRA>\n",
    "        <rmsDec>0.438</rmsDec>\n",
    "        <astCat>Gaia2</astCat>\n",
    "        <mag>21.72</mag>\n",
    "        <band>G</band>\n",
    "      </optical>\n",
    "      <optical>\n",
    "        <provID>2016 SK99</provID>\n",
    "        <trkSub>C8QY322</trkSub>\n",
    "        <mode>CCD</mode>\n",
    "        <stn>G96</stn>\n",
    "        <obsTime>2022-12-25T09:36:34.723Z</obsTime>\n",
    "        <ra>128.147805</ra>\n",
    "        <dec>17.177050</dec>\n",
    "        <rmsRA>0.561</rmsRA>\n",
    "        <rmsDec>0.573</rmsDec>\n",
    "        <astCat>Gaia2</astCat>\n",
    "        <mag>21.31</mag>\n",
    "        <band>G</band>\n",
    "      </optical>\n",
    "</ades>\n",
    "\"\"\"\n",
    "\n",
    "sample_xml_path = os.path.join(tmpdir, \"sample.xml\")\n",
    "with open(sample_xml_path, \"w\") as f:\n",
    "    f.write(sample_xml_content)\n",
    "\n",
    "print(f\"Sample .obs file: {sample_obs_path}\")\n",
    "print(f\"Multiple .obs file: {multiple_obs_path}\")\n",
    "print(f\"Sample .xml file: {sample_xml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e37b3e1",
   "metadata": {},
   "source": [
    "# Basic Usage (1): Classifying a File\n",
    "\n",
    "Perhaps the simplest way to use `digest2` is to call `classify` on an observation file. \n",
    "\n",
    "N.B. In the subsequeent section we provide a more detailed examination of the returned results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "487cf386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(results)=<class 'list'>\n",
      "isinstance(r,ClassificationResult)=True\n",
      "r.designation='K16S99K'\n",
      "Tracklet RMS: 0.73 arcsec\n",
      "\n",
      "Attribute names:\n",
      "\traw type(field)=<class 'dataclasses.Field'>\n",
      "\tnoid type(field)=<class 'dataclasses.Field'>\n",
      "\trms type(field)=<class 'dataclasses.Field'>\n",
      "\trms_prime type(field)=<class 'dataclasses.Field'>\n",
      "\tdesignation type(field)=<class 'dataclasses.Field'>\n",
      "\n",
      "NoID scores (pseudo-probability for each orbit class):\n",
      "  Int :  13.5\n",
      "  NEO :  13.3\n",
      "  N22 :   6.2\n",
      "  N18 :   0.9\n",
      "  MC  :  13.3\n",
      "  Hun :   0.0\n",
      "  Pho :   0.0\n",
      "  MB1 :  72.3\n",
      "  Pal :   0.0\n",
      "  Han :   0.0\n",
      "  MB2 :   0.3\n",
      "  MB3 :   0.0\n",
      "  Hil :   0.0\n",
      "  JTr :   0.0\n",
      "  JFC :   0.4\n"
     ]
    }
   ],
   "source": [
    "results = classify(sample_obs_path, obscodes_path=obscodes_path)\n",
    "r = results[0]\n",
    "\n",
    "print(f\"{type(results)=}\")\n",
    "print(f\"{isinstance(r,ClassificationResult)=}\")\n",
    "print(f\"{r.designation=}\")\n",
    "print(f\"Tracklet RMS: {r.rms:.2f} arcsec\")\n",
    "print()\n",
    "print(\"Attribute names:\")\n",
    "for field in fields(r):\n",
    "    print(f\"\\t{field.name} {type(field)=}\")\n",
    "    \n",
    "print()\n",
    "print(\"NoID scores (pseudo-probability for each orbit class):\")\n",
    "for cls, val in r.noid.items():\n",
    "    print(f\"  {cls:4s}: {val:5.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e063584f",
   "metadata": {},
   "source": [
    "### Understanding the Results\n",
    "\n",
    "Each result is a `ClassificationResult` dataclass with the following attributes:\n",
    "\n",
    "| Attribute | Type | Description |\n",
    "|-----------|------|-------------|\n",
    "| `designation` | `str` | Object designation from the input file |\n",
    "| `rms` | `float` | Great-circle RMS fit of the tracklet (arcseconds) |\n",
    "| `rms_prime` | `float` | Adjusted RMS used internally by the scorer |\n",
    "| `noid` | `Scores` | **NoID scores**: pseudo-probabilities assuming the object is *unidentified* (0--100) |\n",
    "| `raw` | `Scores` | **Raw scores**: pseudo-probabilities using total population (0--100) |\n",
    "| `top_class` | `str` | The class with the highest NoID score |\n",
    "\n",
    "The `Scores` object supports both attribute access (`result.noid.NEO`) and dict-style access (`result.noid[\"NEO\"]`), as well as iteration via `.items()`.\n",
    "\n",
    "The **RAW** scores represent the probability that a given tracklet belongs to each class, making no attempt to consider whether or not the objects in that class have been primarily discovered.\n",
    "\n",
    "The **NoID** scores represent the probability that an unidentified tracklet belongs to each class, accounting for objects already discovered. These are the operationally relevant scores.\n",
    "\n",
    "\n",
    "The 14 orbit classes are:\n",
    "\n",
    "| Abbr | Class | Description |\n",
    "|------|-------|-------------|\n",
    "| Int | MPC Interest | q<1.3 OR e>0.5 OR i>=40 OR Q>10 |\n",
    "| NEO | Near-Earth Object | q < 1.3 AU |\n",
    "| N22 | Large NEO | NEO with H <= 22 |\n",
    "| N18 | Very Large NEO | NEO with H <= 18 |\n",
    "| MC | Mars Crosser | |\n",
    "| Hun | Hungaria | |\n",
    "| Pho | Phocaea | |\n",
    "| MB1 | Inner Main Belt | |\n",
    "| Pal | Pallas family | |\n",
    "| Han | Hansa family | |\n",
    "| MB2 | Middle Main Belt | |\n",
    "| MB3 | Outer Main Belt | |\n",
    "| Hil | Hilda group | |\n",
    "| JTr | Jupiter Trojan | |\n",
    "| JFC | Jupiter Family Comet | |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1fe309",
   "metadata": {},
   "source": [
    "### Raw vs NoID Scores\n",
    "\n",
    "Let's compare both score types to see the difference. Raw scores use the total population; NoID scores use only the *undiscovered* population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "725a68fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class     Raw    NoID\n",
      "----------------------\n",
      " Int     9.5    13.5\n",
      " NEO     9.2    13.3\n",
      " N22     3.3     6.2\n",
      " N18     0.9     0.9\n",
      "  MC    17.3    13.3\n",
      " MB1    66.1    72.3\n",
      " MB2     6.7     0.3\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Class':>4s}  {'Raw':>6s}  {'NoID':>6s}\")\n",
    "print(\"-\" * 22)\n",
    "for cls in r.raw:\n",
    "    raw_val = r.raw[cls]\n",
    "    noid_val = r.noid[cls]\n",
    "    if round(raw_val) > 0 or round(noid_val) > 0:\n",
    "        print(f\"{cls:>4s}  {raw_val:6.1f}  {noid_val:6.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b3feaa",
   "metadata": {},
   "source": [
    "### Under the hood ... \n",
    "\n",
    "When you call `classify` with a filepath as input, under the hood it calls the `Digest2` class as a context manager (`with` statement) so that C resources are automatically released..\n",
    "\n",
    "This loads the population model once and can then classify many tracklets efficiently.\n",
    "\n",
    "The evaluation is then performed using the `classify_file` method.\n",
    "\n",
    "As such, the above call to `classify` is the same as the call below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "306d8fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(results)=<class 'list'>\n",
      "type(r)=<class 'digest2.result.ClassificationResult'>\n",
      "r.designation='K16S99K'\n",
      "Tracklet RMS: 0.73 arcsec\n",
      "\n",
      "Attribute names:\n",
      "\traw\n",
      "\tnoid\n",
      "\trms\n",
      "\trms_prime\n",
      "\tdesignation\n",
      "\n",
      "NoID scores (pseudo-probability for each orbit class):\n",
      "  Int :  13.5\n",
      "  NEO :  13.3\n",
      "  N22 :   6.2\n",
      "  N18 :   0.9\n",
      "  MC  :  13.3\n",
      "  Hun :   0.0\n",
      "  Pho :   0.0\n",
      "  MB1 :  72.3\n",
      "  Pal :   0.0\n",
      "  Han :   0.0\n",
      "  MB2 :   0.3\n",
      "  MB3 :   0.0\n",
      "  Hil :   0.0\n",
      "  JTr :   0.0\n",
      "  JFC :   0.4\n"
     ]
    }
   ],
   "source": [
    "with Digest2(obscodes_path=obscodes_path, repeatable=True) as d2:\n",
    "    results = d2.classify_file(sample_obs_path)\n",
    "\n",
    "r = results[0]\n",
    "\n",
    "print(f\"{type(results)=}\")\n",
    "print(f\"{type(r)=}\")\n",
    "print(f\"{r.designation=}\")\n",
    "print(f\"Tracklet RMS: {r.rms:.2f} arcsec\")\n",
    "print()\n",
    "print(\"Attribute names:\")\n",
    "for field in fields(r):\n",
    "    print(f\"\\t{field.name}\")\n",
    "    \n",
    "print()\n",
    "print(\"NoID scores (pseudo-probability for each orbit class):\")\n",
    "for cls, val in r.noid.items():\n",
    "    print(f\"  {cls:4s}: {val:5.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e631d6ce",
   "metadata": {},
   "source": [
    "# Basic Usage (2): Classifying a File containing Multiple Tracklets\n",
    "\n",
    "If the supplied file contains multiple tracklets (multiple sets of observations, each with different designations/trksubs), then multiple sets of results will be returned, one for each tracklet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03bc3305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "r.designation='K16S99K'\n",
      "Tracklet RMS: 0.73 arcsec\n",
      "\n",
      "NoID scores (pseudo-probability for each orbit class):\n",
      "  Int :  13.5\n",
      "  NEO :  13.3\n",
      "  N22 :   6.2\n",
      "  N18 :   0.9\n",
      "  MC  :  13.3\n",
      "  MB1 :  72.3\n",
      "\n",
      "\n",
      "r.designation='K17R88L'\n",
      "Tracklet RMS: 0.69 arcsec\n",
      "\n",
      "NoID scores (pseudo-probability for each orbit class):\n",
      "  Int : 100.0\n",
      "  NEO : 100.0\n",
      "  N22 :  64.7\n"
     ]
    }
   ],
   "source": [
    "results = classify(multiple_obs_path, obscodes_path=obscodes_path)\n",
    "\n",
    "# Loop over all returned results\n",
    "for r in results:\n",
    "    print(f\"\\n\\n{r.designation=}\")\n",
    "    print(f\"Tracklet RMS: {r.rms:.2f} arcsec\")\n",
    "    print()\n",
    "    print(\"NoID scores (pseudo-probability for each orbit class):\")\n",
    "    for cls, val in r.noid.items():\n",
    "        if round(val) > 0:\n",
    "            print(f\"  {cls:4s}: {val:5.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501dd2e1",
   "metadata": {},
   "source": [
    "# Basic Usage (3): Programmatic Observations\n",
    "\n",
    "Instead of reading from a file, you can construct `Observation` objects directly in Python. This is useful when integrating `digest2` into an automated pipeline.\n",
    "\n",
    "Each observation requires:\n",
    "- `mjd`: Modified Julian Date\n",
    "- `ra`: Right Ascension in degrees\n",
    "- `dec`: Declination in degrees\n",
    "- `obscode`: MPC 3-character observatory code\n",
    "\n",
    "Optional fields include `mag` (magnitude), `band` (photometric band), `rms_ra`, and `rms_dec` (astrometric uncertainties in arcseconds).\n",
    "\n",
    "For quick, one-off classification, the classify() convenience function handles initialization and cleanup automatically. It is polymorphic — it accepts a filepath, a single tracklet, or a batch of tracklets.\n",
    "\n",
    "When we supply a single list of `Observation`s to the `classify` function, it treats them as a single tracklet, i.e. it assumes they are all observations of the same object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48a969f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS: 0.11 arcsec\n",
      "\n",
      "  Int :  96.1\n",
      "  NEO :  95.6\n",
      "  N22 :  29.0\n",
      "  N18 :   5.1\n",
      "  MC  :   4.4\n",
      "  MB2 :   3.0\n",
      "  JFC :   0.7\n"
     ]
    }
   ],
   "source": [
    "# Create observations \n",
    "obs = [\n",
    "    Observation(mjd=59938.384965, ra=128.15118, dec=17.17665,\n",
    "                mag=22.22, band=\"G\", obscode=\"G96\"),\n",
    "    Observation(mjd=59938.395273, ra=128.14899, dec=17.17702,\n",
    "                mag=21.96, band=\"G\", obscode=\"G96\"),\n",
    "    Observation(mjd=59938.400402, ra=128.14780, dec=17.17717,\n",
    "                mag=21.55, band=\"G\", obscode=\"G96\"),\n",
    "]\n",
    "\n",
    "# Call `classify` \n",
    "result = classify(obs, obscodes_path=obscodes_path, repeatable=True)\n",
    "\n",
    "# Print results\n",
    "print(f\"RMS: {result.rms:.2f} arcsec\")\n",
    "print()\n",
    "for cls, val in result.noid.items():\n",
    "    if round(val) > 0:\n",
    "        print(f\"  {cls:4s}: {val:5.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9adc836",
   "metadata": {},
   "source": [
    "### Under the hood ... \n",
    "\n",
    "When you call `classify` with a list of `Observation`s as input, under the hood it calls the `Digest2` class as a context manager, and then the evaluation is then performed using the `classify_tracklet` method.\n",
    "\n",
    "As such, the above call to `classify` is the same as the call below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53f03c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS: 0.11 arcsec\n",
      "\n",
      "  Int :  96.1\n",
      "  NEO :  95.6\n",
      "  N22 :  29.0\n",
      "  N18 :   5.1\n",
      "  MC  :   4.4\n",
      "  MB2 :   3.0\n",
      "  JFC :   0.7\n"
     ]
    }
   ],
   "source": [
    "# Call `classify_tracklet`\n",
    "with Digest2(obscodes_path=obscodes_path, repeatable=True) as d2:\n",
    "    result = d2.classify_tracklet(obs)\n",
    "\n",
    "print(f\"RMS: {result.rms:.2f} arcsec\")\n",
    "print()\n",
    "for cls, val in result.noid.items():\n",
    "    if round(val) > 0:\n",
    "        print(f\"  {cls:4s}: {val:5.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f093e76",
   "metadata": {},
   "source": [
    "# Basic Usage (4): Multiple Tracklets\n",
    "\n",
    "If we supply lists-of-lists-of-`Observation`s to `classify`, then this data is interpreted as being multiple 'tracklets', each of which will be given its own digest2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ed66d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracklet 1: r.noid.NEO=95.6\n",
      "Tracklet 2: r.noid.NEO=100.0\n"
     ]
    }
   ],
   "source": [
    "# Two different tracklets\n",
    "tracklet_1 = [\n",
    "    Observation(mjd=59938.384965, ra=128.15118, dec=17.17665,\n",
    "                mag=22.22, band=\"G\", obscode=\"G96\"),\n",
    "    Observation(mjd=59938.395273, ra=128.14899, dec=17.17702,\n",
    "                mag=21.96, band=\"G\", obscode=\"G96\"),\n",
    "    Observation(mjd=59938.400402, ra=128.14780, dec=17.17717,\n",
    "                mag=21.55, band=\"G\", obscode=\"G96\"),\n",
    "]\n",
    "\n",
    "tracklet_2 = [\n",
    "    Observation(mjd=59938.384965, ra=130.0, dec=20.0,\n",
    "                mag=20.0, obscode=\"G96\"),\n",
    "    Observation(mjd=59938.395273, ra=130.01, dec=20.01,\n",
    "                mag=20.0, obscode=\"G96\"),\n",
    "]\n",
    "\n",
    "# Call classify with 2-tracklet input \n",
    "batch_results = classify([tracklet_1, tracklet_2], obscodes_path=obscodes_path, repeatable=True)\n",
    "\n",
    "# Print results \n",
    "for i, r in enumerate(batch_results):\n",
    "    if r is not None:\n",
    "        neo_score = r.noid.NEO\n",
    "        print(f\"Tracklet {i+1}: {r.noid.NEO=:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027be857",
   "metadata": {},
   "source": [
    "### Under the hood ...\n",
    "\n",
    "When lists-of-lists-of-Observations are passed to classify, under the hood `classify_batch` is called. \n",
    "\n",
    "Hence the call below is the same as the above two-tracklet call to `classify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4aea9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracklet 1: r.noid.NEO=95.6\n",
      "Tracklet 2: r.noid.NEO=100.0\n"
     ]
    }
   ],
   "source": [
    "with Digest2(obscodes_path=obscodes_path, repeatable=True) as d2:\n",
    "    batch_results = d2.classify_batch([tracklet_1, tracklet_2])\n",
    "\n",
    "for i, r in enumerate(batch_results):\n",
    "    if r is not None:\n",
    "        neo_score = r.noid.NEO\n",
    "        print(f\"Tracklet {i+1}: {r.noid.NEO=:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea22673",
   "metadata": {},
   "source": [
    "# Input Formats: 80-Column vs ADES XML\n",
    "\n",
    "The MPC uses two observation formats:\n",
    "1. **MPC 80-column format** (`.obs`): Legacy fixed-width format\n",
    "2. **ADES XML format** (`.xml`): Modern format with per-observation uncertainties\n",
    "\n",
    "The `classify_file()` method auto-detects the format from the file extension. Let's classify the same object in both formats and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d548217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        80-col       XML\n",
      "--------------------------\n",
      " Int      13.5      13.5\n",
      " NEO      13.3      13.3\n",
      " N22       6.2       6.2\n",
      " N18       0.9       0.9\n",
      "  MC      13.3      13.3\n",
      " MB1      72.3      72.5\n",
      "\n",
      "80-col designation: K16S99K\n",
      "XML designation:    C8QY322\n"
     ]
    }
   ],
   "source": [
    "with Digest2(obscodes_path=obscodes_path, repeatable=True) as d2:\n",
    "    results_obs = d2.classify_file(sample_obs_path)\n",
    "    results_xml = d2.classify_file(sample_xml_path)\n",
    "\n",
    "r_obs = results_obs[0]\n",
    "r_xml = results_xml[0]\n",
    "\n",
    "print(f\"{'':>4s}  {'80-col':>8s}  {'XML':>8s}\")\n",
    "print(\"-\" * 26)\n",
    "for cls in r_obs.noid:\n",
    "    v_obs = r_obs.noid[cls]\n",
    "    v_xml = r_xml.noid[cls]\n",
    "    if round(v_obs) > 0 or round(v_xml) > 0:\n",
    "        print(f\"{cls:>4s}  {v_obs:8.1f}  {v_xml:8.1f}\")\n",
    "\n",
    "print(f\"\\n80-col designation: {r_obs.designation}\")\n",
    "print(f\"XML designation:    {r_xml.designation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fb4faf",
   "metadata": {},
   "source": [
    "### 80-col & XML reading using `classify`\n",
    "\n",
    "As the `classify` function calls `classify_file`, it too will automatically process both 80-col and XML flies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bde24a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80-col:r.designation='K16S99K',r.noid.MB1=72.3\n",
      "XML   :r.designation='C8QY322',r.noid.MB1=72.5\n"
     ]
    }
   ],
   "source": [
    "# 80-col : XML Comparison using classify\n",
    "for filepath in [sample_obs_path,sample_xml_path]:\n",
    "    r = classify(filepath, obscodes_path=obscodes_path, repeatable=True)[0]\n",
    "    label = \"XML   :\" if \"xml\" in filepath else \"80-col:\"\n",
    "    print(f\"{label}{r.designation=},{r.noid.MB1=:.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f8280",
   "metadata": {},
   "source": [
    "The scores are very similar between formats. Small differences can arise because:\n",
    "- The ADES XML format includes per-observation astrometric uncertainties (`rmsRA`, `rmsDec`)\n",
    "- The 80-column format relies on observatory-level default errors\n",
    "- Designations may differ (80-column uses packed provisional designation, XML uses `trkSub`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437812ba",
   "metadata": {},
   "source": [
    "# Configuration: Observatory-Level Error Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e6c7e8",
   "metadata": {},
   "source": [
    "\n",
    "### Basic, Per-Observatory, Error Configuration\n",
    "\n",
    "`digest2` sets a base-line assumed error that is applied to all observations from a given observatory location as the basic assumed error *in the abscence of any other error information*. \n",
    "\n",
    "This observatory-specific error, `errorFromConfig`, is defined via the **`MPC.config`** file:\n",
    " - **Default error**: If an `MPC.config` file is **not** supplied, then all observatories will default to `errorFromConfig = 1.0` arc-seconds.\n",
    " - **Per-site errors via `MPC.config`**: Observatory-specific errors, calibrated from historical data, can be supplied to set differing values for `errorFromConfig` for each specified observatory-codes (any observatory codes not specified in MPC.config will default to 1.0 arc-seconds as described above).\n",
    "\n",
    "An example of supplying a smaller-than-the-default-uncertainty for the G96 (Mt. Lemmon) observatory is supplied in the cell below. \n",
    "\n",
    "\n",
    "### Effects of smaller uncertainties \n",
    "\n",
    "The assumed astrometric uncertainty for each observatory significantly affects the scores. \n",
    "\n",
    "Let's compare scores with and without the `MPC.config` file. \n",
    "\n",
    "The bundled `MPC.config` specifies, for example, that observatory G96 (Mt. Lemmon) has a calibrated error of 0.29 arcsec — much better than the 1.0 arcsec default.\n",
    "\n",
    "In the results from the cell below we see that with the default 1.0 arcsec error, the tracklet scores as predominantly main belt (MB1 ~ 85). With the calibrated G96 error of 0.29 arcsec, the position constraints are tighter, and the NEO score increases significantly. This demonstrates why per-site error calibration matters for accurate classification.\n",
    "\n",
    "At the MPC, a NEO score of 65 or above triggers posting to the NEOCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a122ec3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison: Effect of observatory error model\n",
      "Class   Default (1.0\")  MPC.config (0.29\")\n",
      "------------------------------------------\n",
      " Int              2.3                13.5\n",
      " NEO              2.2                13.3\n",
      " N22              1.2                 6.2\n",
      " N18              0.2                 0.9\n",
      "  MC              1.9                13.3\n",
      " MB1             85.3                72.3\n",
      " MB2              2.5                 0.3\n"
     ]
    }
   ],
   "source": [
    "# Create an empty config file (uses default 1.0 arcsec for all observatories)\n",
    "empty_config_path = os.path.join(tmpdir, \"empty.cfg\")\n",
    "with open(empty_config_path, \"w\") as f:\n",
    "    f.write(\"# No per-site errors\\n\")\n",
    "\n",
    "# Classify using the empty config file created above\n",
    "r_default = classify(sample_obs_path, config_path=empty_config_path, obscodes_path=obscodes_path, repeatable=True)[0]\n",
    "\n",
    "# Classfy using the version of MPC.config that comes with digest2 (auto-discovered, includes G96=0.29 arcsec)\n",
    "r_mpc = classify(sample_obs_path, obscodes_path=obscodes_path, repeatable=True)[0]\n",
    "\n",
    "# Print out results \n",
    "header_default = 'Default (1.0\")'\n",
    "header_mpc = 'MPC.config (0.29\")'\n",
    "print(\"Comparison: Effect of observatory error model\")\n",
    "print(f\"{'Class':>4s}  {header_default:>15s}  {header_mpc:>18s}\")\n",
    "print(\"-\" * 42)\n",
    "for cls in r_default.noid:\n",
    "    v_def = r_default.noid[cls]\n",
    "    v_mpc = r_mpc.noid[cls]\n",
    "    if round(v_def) > 0 or round(v_mpc) > 0:\n",
    "        print(f\"{cls:>4s}  {v_def:15.1f}  {v_mpc:18.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a3cfb4",
   "metadata": {},
   "source": [
    "## Custom Configuration Files\n",
    "\n",
    "You can create a custom config file to set observatory errors for your own site. The format is simple: one `obserrXXX=Y.YY` line per observatory, where `XXX` is the MPC observatory code and `Y.YY` is the error in arcseconds.\n",
    "\n",
    "We see in the results of the cell below that tighter uncertainties constrain the range of possible orbits, which can sharpen the classification (e.g. increasing NEO probability for objects on NEO-like trajectories). Looser uncertainties allow more orbit solutions, generally pushing scores toward the most common population (Main Belt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba5095a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class   Tight (0.1\")   Default (1.0\")   Loose (2.0\")\n",
      "----------------------------------------------------\n",
      " Int           13.5              2.3            0.8\n",
      " NEO           13.3              2.2            0.7\n",
      " N22            6.2              1.2            0.4\n",
      " N18            0.9              0.2            0.0\n",
      "  MC           13.3              1.9            0.7\n",
      " MB1           72.3             85.3           67.2\n",
      " MB2            0.3              2.5           26.1\n",
      " MB3            0.0              0.0            4.5\n"
     ]
    }
   ],
   "source": [
    "# Create a custom config with a very tight error for G96\n",
    "tight_config_path = os.path.join(tmpdir, \"tight.cfg\")\n",
    "with open(tight_config_path, \"w\") as f:\n",
    "    f.write(\"obserrG96=0.10\\n\")  # Very precise astrometry\n",
    "\n",
    "# Create a custom config with a very loose error for G96\n",
    "loose_config_path = os.path.join(tmpdir, \"loose.cfg\")\n",
    "with open(loose_config_path, \"w\") as f:\n",
    "    f.write(\"obserrG96=2.0\\n\")  # Poor astrometry\n",
    "\n",
    "r_tight = classify(sample_obs_path, config_path=tight_config_path, obscodes_path=obscodes_path, repeatable=True)[0]\n",
    "r_loose = classify(sample_obs_path, config_path=loose_config_path, obscodes_path=obscodes_path, repeatable=True)[0]\n",
    "\n",
    "h_tight = 'Tight (0.1\")'\n",
    "h_default = 'Default (1.0\")'\n",
    "h_loose = 'Loose (2.0\")'\n",
    "print(f\"{'Class':>4s}  {h_tight:>13s}  {h_default:>15s}  {h_loose:>13s}\")\n",
    "print(\"-\" * 52)\n",
    "for cls in r_tight.noid:\n",
    "    v_t = r_tight.noid[cls]\n",
    "    v_d = r_default.noid[cls]\n",
    "    v_l = r_loose.noid[cls]\n",
    "    if round(v_t) > 0 or round(v_d) > 0 or round(v_l) > 0:\n",
    "        print(f\"{cls:>4s}  {v_t:13.1f}  {v_d:15.1f}  {v_l:13.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09e6127",
   "metadata": {},
   "source": [
    "# Advanced, Per-Observation, Error Configuration\n",
    "\n",
    "<span style='color:red'> **WARNING:** The behavior of the per-observation error model is highly non-trivial </span>\n",
    "\n",
    "**Per-observation errors via ADES**: When using ADES format or constructing observations programmatically, you can provide per-observation astrometric uncertainties (`rms_ra`, `rms_dec`). If the user supplies these individual, per-observation, uncertainties in the ADES file of observations, they will be used as the errors in `digest2`, allowing different errors to be associated with each different observation. \n",
    "\n",
    "Set `is_ades=True` to tell `digest2` to use the per-observation RMS values rather than the configured site error.\n",
    "\n",
    "However, by default the overall observatory-level error specification from the MPC.config file, `errorFromConfig`, will frequently over-ride the value of the detailed observation-level errors supplied from the ADES file. \n",
    "In particular: \n",
    " - **Error Floor**\n",
    "   - The value of `errorFromConfig` from the config file (whether they are the default `1.0\"`, or some explicitly provided values) is used as a *floor*, so per-obs errors will only be used if they are *higher* than the `errorFromConfig` values.\n",
    "   - <span style='color:red'> I.e. If the supplied per-observation RMS is **smaller** than the value in the config file, the supplied per-observation RMS will be ignored, and the default value of `errorFromConfig` used, even if `is_ades=True`. </span>\n",
    " - **Error Ceiling**\n",
    "   - `digest2` will also, by *default*, impose a *ceiling* on the rms value of `5 * errorFromConfig`. This is done in `updateRMSValues`.\n",
    "   - <span style='color:red'> I.e. If the supplied per-observation RMS is **larger** than `5*errorFromConfig`, then *by default* the supplied per-observation RMS will be ignored, and a value of `5*errorFromConfig` will be used, even if `is_ades=True`. </span>\n",
    " - **Ceiling Removal**\n",
    "   - There is a `noThreshold` variable that can be supplied that will *remove the ceiling*. By default `noThreshold=False`, and a threhold (ceiling) *is* applied.\n",
    "   - <span style='color:red'> I.e. If we supply a `noThreshold=True` argument, then the threhold (ceiling) will *not* be applied. </span>\n",
    "\n",
    "Thus, in practice, if you want digest2 to *always* use the exact RMS values supplied in the ADES file, you would need to \n",
    "1. Set `is_ades=True` to tell `digest2` to use the per-observation RMS values\n",
    "2. Define default error values at/close-to zero in the MPC.config file.\n",
    "3. Set `noThreshold=True` to remove any ceiling. \n",
    "\n",
    "N.B. The main practical reason for use of `errorFromConfig` as a floor, is to prevent unrealistically small errors in ADES files accidentally skewing the digest2 score. \n",
    "\n",
    "In the cell(s) below we demonstrate the effect of passing per-observation uncertainties in various scenarios, and demonstrate that the effect depends upon (a) the values supplied in the config file, and (b) the value of the `noThreshold` boolean. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b44b955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[91mEmpty Config File => Default 1\" Uncertainty\u001b[0m\n",
      "\u001b[91mWhen the supplied per-observation RMS is **smaller** than the value in the config file, the supplied per-observation RMS is ignored.\u001b[0m\n",
      "\n",
      "Class   No per-obs RMS  Large per-obs RMS  Small per-obs RMS\n",
      "------------------------------------------------------------\n",
      " Int              2.2                0.6                2.2\n",
      " NEO              2.2                0.6                2.2\n",
      " N22              1.0                0.3                1.0\n",
      "  MC              1.9                0.6                1.9\n",
      " MB1             94.1               62.2               94.1\n",
      " MB2              2.4               19.9                2.4\n",
      " MB3              0.1               15.8                0.1\n",
      "\u001b[91mUsing an absurdly small RMS value in the config files allows very small per-observation RMS values to take effect.\u001b[0m\n",
      "\u001b[91mNB The printed `No per-obs RMS` value uses the same 1\" config as above.\u001b[0m\n",
      "\n",
      "Class   No per-obs RMS  Large per-obs RMS  Small per-obs RMS\n",
      "------------------------------------------------------------\n",
      " Int              2.2                0.6               95.9\n",
      " NEO              2.2                0.6               95.8\n",
      " N22              1.0                0.3               27.0\n",
      "  MC              1.9                0.6                4.2\n",
      " MB1             94.1               62.2                0.0\n",
      " MB2              2.4               19.9                3.0\n",
      " MB3              0.1               15.8                0.0\n",
      "\u001b[91mUsing an absurdly small RMS value in the config files allows very small per-observation RMS values to take effect.\u001b[0m\n",
      "\u001b[91mBut if `no_threshold=False`, large per-obs RMS values will be capped at a ceiling value.\u001b[0m\n",
      "\n",
      "Class   No per-obs RMS  Large per-obs RMS  Small per-obs RMS\n",
      "------------------------------------------------------------\n",
      " Int              2.2               15.7               95.9\n",
      " NEO              2.2               15.6               95.8\n",
      " N22              1.0                5.4               27.0\n",
      " N18              0.1                1.0                3.7\n",
      "  MC              1.9                0.8                4.2\n",
      " MB1             94.1               83.4                0.0\n",
      " MB2              2.4                0.5                3.0\n"
     ]
    }
   ],
   "source": [
    "# Observations WITHOUT per-observation uncertainties\n",
    "obs_no_rms = [\n",
    "    Observation(mjd=59938.384965, ra=128.15118, dec=17.17665, mag=22.22, band=\"G\", obscode=\"G96\"),\n",
    "    Observation(mjd=59938.395273, ra=128.14899, dec=17.17702, mag=21.96, band=\"G\", obscode=\"G96\"),\n",
    "    Observation(mjd=59938.400402, ra=128.14780, dec=17.17717, mag=21.55, band=\"G\", obscode=\"G96\"),\n",
    "]\n",
    "\n",
    "# Same observations WITH LARGE per-observation uncertainties (from ADES)\n",
    "# - These uncertainties are larger than the default 1 arc-sec uncertainty that is assumed when the config file is empty\n",
    "obs_with_large_rms = [\n",
    "    Observation(mjd=59938.384965, ra=128.15118, dec=17.17665, mag=22.22, band=\"G\", obscode=\"G96\", rms_ra=2.147, rms_dec=2.101),\n",
    "    Observation(mjd=59938.395273, ra=128.14899, dec=17.17702, mag=21.96, band=\"G\", obscode=\"G96\", rms_ra=2.131, rms_dec=2.138),\n",
    "    Observation(mjd=59938.400402, ra=128.14780, dec=17.17717, mag=21.55, band=\"G\", obscode=\"G96\", rms_ra=2.161, rms_dec=2.173),\n",
    "]\n",
    "\n",
    "# Same observations WITH SMALL per-observation uncertainties (from ADES)\n",
    "# - These uncertainties are smaller than the default 1 arc-sec uncertainty that is assumed when the config file is empty\n",
    "obs_with_small_rms = [\n",
    "    Observation(mjd=59938.384965, ra=128.15118, dec=17.17665, mag=22.22, band=\"G\", obscode=\"G96\", rms_ra=0.147, rms_dec=0.101),\n",
    "    Observation(mjd=59938.395273, ra=128.14899, dec=17.17702, mag=21.96, band=\"G\", obscode=\"G96\", rms_ra=0.131, rms_dec=0.138),\n",
    "    Observation(mjd=59938.400402, ra=128.14780, dec=17.17717, mag=21.55, band=\"G\", obscode=\"G96\", rms_ra=0.161, rms_dec=0.173),\n",
    "]\n",
    "\n",
    "# As above, create an empty config file (uses default 1.0 arcsec for all observatories)\n",
    "empty_config_path = os.path.join(tmpdir, \"empty.cfg\")\n",
    "with open(empty_config_path, \"w\") as f:\n",
    "    f.write(\"# No per-site errors\\n\")\n",
    "\n",
    "# Create a custom config with an inconceivably tight error for G96\n",
    "absurd_config_path = os.path.join(tmpdir, \"absurd.cfg\")\n",
    "with open(absurd_config_path, \"w\") as f:\n",
    "    f.write(\"obserrG96=0.001\\n\")  # Unbelievably precise astrometry\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Classify with & without the provided rms, comparing against the DEFAULT (1\") config\n",
    "with Digest2(config_path=empty_config_path, obscodes_path=obscodes_path, repeatable=True) as d2:\n",
    "    r_no_rms = d2.classify_tracklet(obs_no_rms)  # empty config file causes digest2 to use default 1.0 arcsec for all observatories\n",
    "    r_with_large_rms = d2.classify_tracklet(obs_with_large_rms, is_ades=True)\n",
    "    r_with_small_rms = d2.classify_tracklet(obs_with_small_rms, is_ades=True)\n",
    "\n",
    "print('\\033[91m' + 'Empty Config File => Default 1\" Uncertainty' + '\\033[0m')\n",
    "print('\\033[91m' + 'When the supplied per-observation RMS is **smaller** than the value in the config file, the supplied per-observation RMS is ignored.' + '\\033[0m')\n",
    "print()\n",
    "print(f\"{'Class':>4s}  {'No per-obs RMS':>15s}  {'Large per-obs RMS':>17s}  {'Small per-obs RMS':>17s}\")\n",
    "print(\"-\" * 60)\n",
    "for cls in r_no_rms.noid:\n",
    "    v1 = r_no_rms.noid[cls]\n",
    "    v2 = r_with_large_rms.noid[cls]\n",
    "    v3 = r_with_small_rms.noid[cls]\n",
    "    if round(v1) > 0 or round(v2) > 0:\n",
    "        print(f\"{cls:>4s}  {v1:15.1f}  {v2:17.1f}  {v3:17.1f}\")\n",
    "\n",
    "\n",
    "\n",
    "# Classify with & without the provided rms, this time using the *absurd_config_path* as the \"floor\" \n",
    "# - We set `no_threshold=True` so that the LARGE per-obs rms is used  \n",
    "with Digest2(config_path=absurd_config_path, obscodes_path=obscodes_path, repeatable=True, no_threshold=True) as d2:\n",
    "    r_with_large_rms = d2.classify_tracklet(obs_with_large_rms, is_ades=True)\n",
    "    r_with_small_rms = d2.classify_tracklet(obs_with_small_rms, is_ades=True)\n",
    "\n",
    "print('\\033[91m' + 'Using an absurdly small RMS value in the config files allows very small per-observation RMS values to take effect.' + '\\033[0m')\n",
    "print('\\033[91m' + 'NB The printed `No per-obs RMS` value uses the same 1\" config as above.' + '\\033[0m')\n",
    "print()\n",
    "print(f\"{'Class':>4s}  {'No per-obs RMS':>15s}  {'Large per-obs RMS':>17s}  {'Small per-obs RMS':>17s}\")\n",
    "print(\"-\" * 60)\n",
    "for cls in r_no_rms.noid:\n",
    "    v1 = r_no_rms.noid[cls]\n",
    "    v2 = r_with_large_rms.noid[cls]\n",
    "    v3 = r_with_small_rms.noid[cls]\n",
    "    if round(v1) > 0 or round(v2) > 0:\n",
    "        print(f\"{cls:>4s}  {v1:15.1f}  {v2:17.1f}  {v3:17.1f}\")\n",
    "\n",
    "\n",
    "# Classify with & without the provided rms, this time using the *absurd_config_path* as the \"floor\" \n",
    "# - We set `no_threshold=False` so that the LARGE per-obs rms is IGNORED (5*config-value will be used)   \n",
    "with Digest2(config_path=absurd_config_path, obscodes_path=obscodes_path, repeatable=True, no_threshold=False) as d2:\n",
    "    r_with_large_rms = d2.classify_tracklet(obs_with_large_rms, is_ades=True)\n",
    "    r_with_small_rms = d2.classify_tracklet(obs_with_small_rms, is_ades=True)\n",
    "\n",
    "print('\\033[91m' + 'Using an absurdly small RMS value in the config files allows very small per-observation RMS values to take effect.' + '\\033[0m')\n",
    "print('\\033[91m' + 'But if `no_threshold=False`, large per-obs RMS values will be capped at a ceiling value.' + '\\033[0m')\n",
    "print()\n",
    "print(f\"{'Class':>4s}  {'No per-obs RMS':>15s}  {'Large per-obs RMS':>17s}  {'Small per-obs RMS':>17s}\")\n",
    "print(\"-\" * 60)\n",
    "for cls in r_no_rms.noid:\n",
    "    v1 = r_no_rms.noid[cls]\n",
    "    v2 = r_with_large_rms.noid[cls]\n",
    "    v3 = r_with_small_rms.noid[cls]\n",
    "    if round(v1) > 0 or round(v2) > 0:\n",
    "        print(f\"{cls:>4s}  {v1:15.1f}  {v2:17.1f}  {v3:17.1f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce0301f",
   "metadata": {},
   "source": [
    "# Class Filtering\n",
    "\n",
    "If you only care about specific orbit classes, use the `classes` parameter to compute only those scores. This can be useful for focused analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d608f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Digest2(obscodes_path=obscodes_path, repeatable=True) as d2:\n",
    "    result = d2.classify_tracklet(obs, classes=[\"NEO\", \"MC\", \"MB1\"])\n",
    "\n",
    "print(\"Filtered classification (NEO, MC, MB1 only):\")\n",
    "print(f\"  NEO: {result.noid.NEO:.1f}\")\n",
    "print(f\"  MC:  {result.noid.MC:.1f}\")\n",
    "print(f\"  MB1: {result.noid.MB1:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deba6ac",
   "metadata": {},
   "source": [
    "Note that when filtering, scores are renormalized over the selected classes only, so the values will differ from the unfiltered case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aef1dd3",
   "metadata": {},
   "source": [
    "# Parsing Observation Files\n",
    "\n",
    "The parsing functions can be used independently, which is useful for inspecting observations before classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2136f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse MPC 80-column file\n",
    "tracklets_80 = parse_mpc80_file(sample_obs_path)\n",
    "\n",
    "for desig, obs_list in tracklets_80.items():\n",
    "    print(f\"Designation: '{desig.strip()}'  ({len(obs_list)} observations)\")\n",
    "    for o in obs_list:\n",
    "        print(f\"  MJD={o.mjd:.6f}  RA={o.ra:.5f}  Dec={o.dec:.5f}  \"\n",
    "              f\"Mag={o.mag:.2f}  Site={o.obscode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ece45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse ADES XML file\n",
    "tracklets_xml = parse_ades_xml(sample_xml_path)\n",
    "\n",
    "for desig, obs_list in tracklets_xml.items():\n",
    "    print(f\"Designation: '{desig}'  ({len(obs_list)} observations)\")\n",
    "    for o in obs_list:\n",
    "        print(f\"  MJD={o.mjd:.6f}  RA={o.ra:.6f}  Dec={o.dec:.6f}  \"\n",
    "              f\"Mag={o.mag:.2f}  Site={o.obscode}  \"\n",
    "              f\"rmsRA={o.rms_ra:.3f}  rmsDec={o.rms_dec:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9213ed72",
   "metadata": {},
   "source": [
    "Note that ADES XML provides per-observation astrometric uncertainties (`rmsRA`, `rmsDec`), which the 80-column format does not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05567525",
   "metadata": {},
   "source": [
    "# Error Handling\n",
    "\n",
    "`digest2` raises standard Python exceptions for common error cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5249250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error: too few observations (need at least 2)\n",
    "try:\n",
    "    with Digest2(obscodes_path=obscodes_path, repeatable=True) as d2:\n",
    "        d2.classify_tracklet([Observation(mjd=59938.0, ra=128.0, dec=17.0, obscode=\"G96\")])\n",
    "except (RuntimeError, ValueError) as e:\n",
    "    print(f\"{type(e).__name__}: {e}\")\n",
    "\n",
    "# Error: invalid orbit class\n",
    "try:\n",
    "    with Digest2(obscodes_path=obscodes_path, repeatable=True) as d2:\n",
    "        d2.classify_tracklet(obs, classes=[\"INVALID\"])\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError: {e}\")\n",
    "\n",
    "# Error: using a closed instance\n",
    "try:\n",
    "    d2 = Digest2(obscodes_path=obscodes_path)\n",
    "    d2.close()\n",
    "    d2.classify_tracklet(obs)\n",
    "except RuntimeError as e:\n",
    "    print(f\"RuntimeError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97654bbe",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "The `digest2` Python package provides fast orbit classification for short-arc astrometric tracklets. Key points:\n",
    "\n",
    "- **Install**: `pip install digest2`\n",
    "- **Basic usage**: `Digest2` class as a context manager, or `classify()` one-shot function\n",
    "- **Input formats**: MPC 80-column (`.obs`) and ADES XML (`.xml`) files, or programmatic `Observation` objects\n",
    "- **Configuration**: Per-site observatory errors via `MPC.config` (bundled) or custom config files\n",
    "- **Uncertainties matter**: Smaller assumed errors produce tighter orbital constraints and sharper classification\n",
    "- **NEO threshold**: Objects with NoID NEO score ≥ 65 are posted to the MPC's NEO Confirmation Page\n",
    "\n",
    "For more information:\n",
    "- [digest2 documentation on GitHub](https://github.com/Smithsonian/mpc-public/tree/main/digest2)\n",
    "- [NEO Confirmation Page](https://minorplanetcenter.net/iau/NEO/toconfirm_tabular.html)\n",
    "- [Keys et al. 2019](https://arxiv.org/abs/1904.09188) — Algorithm description\n",
    "\n",
    "For questions or feedback, contact the MPC via the [Jira Helpdesk](https://mpc-service.atlassian.net/servicedesk/customer/portal/13/create/148)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (digest2-dev)",
   "language": "python",
   "name": "digest2-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
